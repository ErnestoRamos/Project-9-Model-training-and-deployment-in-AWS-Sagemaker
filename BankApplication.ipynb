{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-plenty",
   "metadata": {},
   "source": [
    "##  Steps:\n",
    "\n",
    "1. Importing necessary Libraries\n",
    "2. Creating S3 bucket\n",
    "3. Mapping train And Test Data in S3\n",
    "4. Split data into train, val, test; Use sagemaker inbuilt Xgboost algo to fit the data and validate on val set\n",
    "5. Map path of the models in S3\n",
    "6. Predict on test set and create confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "external-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "front-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "complete-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "# create s3 bucket\n",
    "\n",
    "bucket_name = 'eramosbankapplication' \n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "signal-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://eramosbankapplication/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "\n",
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surface-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "\n",
    "import pandas as pd\n",
    "import urllib\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "    \n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "    \n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respective-lighting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>y_no</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  campaign  pdays  previous  no_previous_contact  not_working  \\\n",
       "0       56         1    999         0                    1            0   \n",
       "1       57         1    999         0                    1            0   \n",
       "2       37         1    999         0                    1            0   \n",
       "3       40         1    999         0                    1            0   \n",
       "4       56         1    999         0                    1            0   \n",
       "...    ...       ...    ...       ...                  ...          ...   \n",
       "41183   73         1    999         0                    1            1   \n",
       "41184   46         1    999         0                    1            0   \n",
       "41185   56         2    999         0                    1            1   \n",
       "41186   44         1    999         0                    1            0   \n",
       "41187   74         3    999         1                    1            1   \n",
       "\n",
       "       job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  ...  \\\n",
       "0               0                0                 0              1  ...   \n",
       "1               0                0                 0              0  ...   \n",
       "2               0                0                 0              0  ...   \n",
       "3               1                0                 0              0  ...   \n",
       "4               0                0                 0              0  ...   \n",
       "...           ...              ...               ...            ...  ...   \n",
       "41183           0                0                 0              0  ...   \n",
       "41184           0                1                 0              0  ...   \n",
       "41185           0                0                 0              0  ...   \n",
       "41186           0                0                 0              0  ...   \n",
       "41187           0                0                 0              0  ...   \n",
       "\n",
       "       day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                    0                1                0                0   \n",
       "1                    0                1                0                0   \n",
       "2                    0                1                0                0   \n",
       "3                    0                1                0                0   \n",
       "4                    0                1                0                0   \n",
       "...                ...              ...              ...              ...   \n",
       "41183                1                0                0                0   \n",
       "41184                1                0                0                0   \n",
       "41185                1                0                0                0   \n",
       "41186                1                0                0                0   \n",
       "41187                1                0                0                0   \n",
       "\n",
       "       day_of_week_wed  poutcome_failure  poutcome_nonexistent  \\\n",
       "0                    0                 0                     1   \n",
       "1                    0                 0                     1   \n",
       "2                    0                 0                     1   \n",
       "3                    0                 0                     1   \n",
       "4                    0                 0                     1   \n",
       "...                ...               ...                   ...   \n",
       "41183                0                 0                     1   \n",
       "41184                0                 0                     1   \n",
       "41185                0                 0                     1   \n",
       "41186                0                 0                     1   \n",
       "41187                0                 1                     0   \n",
       "\n",
       "       poutcome_success  y_no  y_yes  \n",
       "0                     0     1      0  \n",
       "1                     0     1      0  \n",
       "2                     0     1      0  \n",
       "3                     0     1      0  \n",
       "4                     0     1      0  \n",
       "...                 ...   ...    ...  \n",
       "41183                 0     0      1  \n",
       "41184                 0     1      0  \n",
       "41185                 0     1      0  \n",
       "41186                 0     0      1  \n",
       "41187                 0     1      0  \n",
       "\n",
       "[41188 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data\n",
    "\n",
    "# last two columns show the outcome - whether the consumer bought the application\n",
    "# since it is in a one-hot encoded format, we can drop one and keep the other --- i.e. keep y_yes (consumer bought app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "peaceful-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26360, 61) (6590, 61) (8238, 61)\n"
     ]
    }
   ],
   "source": [
    "# split downloaded data into train, val, test split\n",
    "# not splitting it in typical x_train, y_train, x_test, y_test because we instead want to save the train and test data back to ..\n",
    "# .. s3 first then use each of those files separately \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "trainval_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.8 * len(model_data))])\n",
    "train_data, val_data = np.split(trainval_data.sample(frac=1, random_state=1729), [int(0.8 * len(trainval_data))])\n",
    "\n",
    "print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "animal-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Train Into Indicated Bucket\n",
    "\n",
    "# keep only one of the last two cols which show the outcome of interest\n",
    "\n",
    "import os\n",
    "\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dominant-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Train Into Indicated Bucket\n",
    "\n",
    "pd.concat([val_data['y_yes'], val_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('val.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'val/val.csv')).upload_file('val.csv')\n",
    "s3_input_val = sagemaker.TrainingInput(s3_data='s3://{}/{}/val'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "human-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Into Indicated Bucket\n",
    "\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-wiring",
   "metadata": {},
   "source": [
    "# Let's use the inbuilt Xgboost algo provided by Sagemaker\n",
    "\n",
    "### these inbuilt algos are containers which need to be pulled in order to be used\n",
    "### Xgboost can also be run as a framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chicken-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = get_image_uri(boto3.Session().region_name,\n",
    "                          'xgboost', \n",
    "                          repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seeing-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparams\n",
    "# these were detemrined locally\n",
    "# we do not want to do the tuning on sagemaker due to increased costs\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indian-industry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_use_spot_instances has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_wait has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=300,\n",
    "                                          train_max_wait=600)\n",
    "\n",
    "# Billing is based on training duration\n",
    "# last 3 params help to limit costs with training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "verified-stanley",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-24 04:18:19 Starting - Starting the training job...\n",
      "2021-03-24 04:18:42 Starting - Launching requested ML instancesProfilerReport-1616559498: InProgress\n",
      "......\n",
      "2021-03-24 04:19:42 Starting - Preparing the instances for training...\n",
      "2021-03-24 04:20:11 Downloading - Downloading input data...\n",
      "2021-03-24 04:20:42 Training - Downloading the training image...\n",
      "2021-03-24 04:21:20 Uploading - Uploading generated training model.\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[04:21:16] 26360x59 matrix with 1555240 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[04:21:16] 6590x59 matrix with 388810 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 26360 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 6590 rows\u001b[0m\n",
      "\u001b[34m[04:21:16] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.09935#011validation-error:0.11305\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.09742#011validation-error:0.11108\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.09716#011validation-error:0.10956\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.09734#011validation-error:0.11017\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.09742#011validation-error:0.10880\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.09746#011validation-error:0.10819\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.09719#011validation-error:0.10774\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.09734#011validation-error:0.10789\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.09719#011validation-error:0.10819\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.09685#011validation-error:0.10744\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.09704#011validation-error:0.10759\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.09689#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.09659#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.09647#011validation-error:0.10865\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.09662#011validation-error:0.10926\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.09628#011validation-error:0.10926\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.09606#011validation-error:0.10880\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.09590#011validation-error:0.10865\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.09606#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.09602#011validation-error:0.10895\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.09567#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.09560#011validation-error:0.10804\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09541#011validation-error:0.10835\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.09530#011validation-error:0.10804\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.09552#011validation-error:0.10835\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09549#011validation-error:0.10835\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.09545#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09560#011validation-error:0.10865\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.09552#011validation-error:0.10956\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.09511#011validation-error:0.10910\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.09533#011validation-error:0.10941\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.09526#011validation-error:0.10910\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.09530#011validation-error:0.11002\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.09526#011validation-error:0.10956\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.09541#011validation-error:0.10910\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09503#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.09503#011validation-error:0.10850\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.09507#011validation-error:0.10865\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.09507#011validation-error:0.10865\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.09514#011validation-error:0.10774\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09522#011validation-error:0.10819\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.09514#011validation-error:0.10819\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.09484#011validation-error:0.10744\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09507#011validation-error:0.10744\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.09480#011validation-error:0.10759\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.09484#011validation-error:0.10774\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.09518#011validation-error:0.10804\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.09488#011validation-error:0.10819\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.09484#011validation-error:0.10819\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.09473#011validation-error:0.10789\u001b[0m\n",
      "\n",
      "2021-03-24 04:21:42 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 38\n",
      "Managed Spot Training savings: 50.6%\n"
     ]
    }
   ],
   "source": [
    "# fit the train data on the model and validate on val set \n",
    "estimator.fit({'train': s3_input_train,'validation': s3_input_val})\n",
    "\n",
    "# input is taken from S3 bucket\n",
    "\n",
    "# note that train error and val error is decreasing with every iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-elements",
   "metadata": {},
   "source": [
    "## Let's deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "found-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-express",
   "metadata": {},
   "source": [
    "## Predict on the test data and output confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pacific-survivor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8238,)\n"
     ]
    }
   ],
   "source": [
    "# serializer is essential for making predictions\n",
    "\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #drop outcomes and load the data into an array\n",
    "# xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type since we are working with a csv file\n",
    "\n",
    "\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict! Decoding is required to interpret serialzed findings\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "\n",
    "\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "capital-brain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20057243, 0.04776593, 0.01932938, ..., 0.0384167 , 0.04332333,\n",
       "       0.04149   ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "checked-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.4%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    90% (7182)    33% (88)\n",
      "Purchase        10% (787)     67% (181) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from AWS documentation \n",
    "\n",
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-brief",
   "metadata": {},
   "source": [
    "### TP = Predicted purchase /  purchase   ; TN = Predicted no purchase /  no purchase\n",
    "### FP = Predicted purchae / no purchase ; FN = Predicted no purchase / purchase \n",
    "\n",
    "\n",
    "\n",
    "### Precision is: TP / TP + FP ----> 181 / (181 + 88) =  67%\n",
    "### Recall is: TP / TP + FN ---->  181 / (181  + 787) = 19%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-shape",
   "metadata": {},
   "source": [
    "## Deleting the endpoints (model and s3 bucket) to prevent additional charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "brief-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'PT6C2N95J33A037S',\n",
       "   'HostId': 'qs4LYpuNJ5m/QOSohjb2zYXqUSwuTPZFu/W7wGsnMZmd3yv88kSr0PyI5sX5lsRD8gu22SIvSxs=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'qs4LYpuNJ5m/QOSohjb2zYXqUSwuTPZFu/W7wGsnMZmd3yv88kSr0PyI5sX5lsRD8gu22SIvSxs=',\n",
       "    'x-amz-request-id': 'PT6C2N95J33A037S',\n",
       "    'date': 'Wed, 24 Mar 2021 04:47:23 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/profiler-output/system/incremental/2021032404/1616559600.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/profiler-output/system/incremental/2021032404/1616559660.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/val/val.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-03-24-04-18-18-842/rule-output/ProfilerReport-1616559498/profiler-output/profiler-reports/LowGPUUtilization.json'}]}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
